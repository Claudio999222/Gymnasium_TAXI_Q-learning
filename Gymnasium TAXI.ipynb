{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c6264de-e06b-4230-8e80-42b49ee471ec",
   "metadata": {},
   "source": [
    "### importo l'ambiente TAXI da gymnasium creo un envoirement, lo resetto e con il comando render visualizzo l'ambiente  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6336469c-8843-43e0-9671-bdefdfbcbcc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|R: | : :\u001b[34;1mG\u001b[0m|\n",
      "| : | : : |\n",
      "| : : :\u001b[43m \u001b[0m: |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import random \n",
    "from IPython.display import clear_output\n",
    "from time import sleep\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "env = gym.make(\"Taxi-v3\", render_mode=\"ansi\").env\n",
    "\n",
    "env.reset()\n",
    "print(env.render())\n",
    "# Le 4 lettere rappresentano la postazione dove puo essere il passeggero e allo stesso tempo dove puo essere portato il giallo e' il taxi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27211240-2e65-4774-b12e-65e93af543ea",
   "metadata": {},
   "source": [
    "### Esplorazione dell'ambiente per mappare stati e azioni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd8e76ab-3736-4a35-a836-a9f253418af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action SpaceDiscrete(6)\n",
      "Che sono le azioni possibili\n",
      "State Space Discrete(500)\n",
      "Che sono i stati possibili\n"
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "env.render()\n",
    "\n",
    "print(\"Action Space{}\".format(env.action_space) )\n",
    "print(\"Che sono le azioni possibili\")\n",
    "print(\"State Space {}\".format(env.observation_space))\n",
    "print(\"Che sono i stati possibili\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d115333-746b-4e70-b77e-55298fbd5179",
   "metadata": {},
   "source": [
    "### manipolazioni all'interno di uno stato \n",
    "#### don decode decodifichiamo lo stato con le variabili che lo definiscono \n",
    "\n",
    "#### creazione del mio stato partendo da determinate condizioni nelle variabili"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f97073f5-b16a-4d5e-af41-71bc68d782e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84 \n",
      "\n",
      "0\n",
      "4\n",
      "1\n",
      "0\n",
      "\n",
      " imposto uno stato manualmente\n",
      "State: 364 \n",
      "\n",
      "+---------+\n",
      "|\u001b[35mR\u001b[0m: | : :\u001b[34;1m\u001b[43mG\u001b[0m\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/claudio/Scrivania/Project/venv/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.s to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.s` for environment variables or `env.get_wrapper_attr('s')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/claudio/Scrivania/Project/venv/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.decode to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.decode` for environment variables or `env.get_wrapper_attr('decode')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/claudio/Scrivania/Project/venv/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.encode to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.encode` for environment variables or `env.get_wrapper_attr('encode')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "print(env.s, '\\n')\n",
    "for el in env.decode(env.s):\n",
    "    print(el)\n",
    "\n",
    "print('\\n imposto uno stato manualmente')\n",
    "state = env.encode(3, 3, 1, 0)\n",
    "print(\"State:\", state, '\\n')\n",
    "\n",
    "env.s = state\n",
    "print(env.render())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c32843d-ccb4-441f-bb4a-d8442ea27ee2",
   "metadata": {},
   "source": [
    "### Esplorazione reward table \n",
    "#### e' un dizionario strutturato con action : [(probabilty, nextstate, reward, done)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "209aa374-b16a-41b3-8661-946f059fbcb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/claudio/Scrivania/Project/venv/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.P to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.P` for environment variables or `env.get_wrapper_attr('P')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: [(1.0, 464, -1, False)],\n",
       " 1: [(1.0, 264, -1, False)],\n",
       " 2: [(1.0, 384, -1, False)],\n",
       " 3: [(1.0, 364, -1, False)],\n",
       " 4: [(1.0, 364, -10, False)],\n",
       " 5: [(1.0, 364, -10, False)]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.P[364]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a81829-36e9-4a50-82e2-ae0033510763",
   "metadata": {},
   "source": [
    "### Simulazione random dell'agente che si muove nell'ambiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "992b4f3b-42d7-4cdb-b064-c6eb633167e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steps: 2562\n",
      "penalita': 824\n"
     ]
    }
   ],
   "source": [
    "env.s = 322\n",
    "\n",
    "steps, penalties, reward = 0, 0, 0\n",
    "frames = []\n",
    "done = False\n",
    "while not done:\n",
    "    action = env.action_space.sample()\n",
    "    state, reward , terminated, truncated, info = env.step(action)\n",
    "    if reward ==-10:\n",
    "        penalties += 1\n",
    "\n",
    "    frames.append({\n",
    "        'frame' : env.render(),\n",
    "        'state' : state,\n",
    "        'action': action,\n",
    "        'reward' : reward\n",
    "        }\n",
    "                 )\n",
    "\n",
    "    steps += 1\n",
    "    done = terminated or truncated \n",
    "\n",
    "print(\"steps: {}\".format(steps))\n",
    "print(\"penalita': {}\".format(penalties))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ded0ebc-36a6-4ca9-902c-738aa98cf365",
   "metadata": {},
   "source": [
    "### Animazione della simulazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76d21d88-e6b0-45fe-b850-708ca8bfece6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|\u001b[35mR\u001b[0m: | : :\u001b[34;1mG\u001b[0m|\n",
      "| : |\u001b[43m \u001b[0m: : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "  (Pickup)\n",
      "\n",
      "step       :1500\n",
      "stato      :144\n",
      "azione     :4\n",
      "ricompensa :-10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def print_frames(frames):\n",
    "    for i, frame in enumerate(frames):\n",
    "        clear_output(wait=True)\n",
    "        print(frame['frame'])\n",
    "        print(f\"step       :{i+1}\")\n",
    "        print(f\"stato      :{frame['state']}\")\n",
    "        print(f\"azione     :{frame['action']}\")\n",
    "        print(f\"ricompensa :{frame['reward']}\")\n",
    "        sleep(.0001)\n",
    "\n",
    "print_frames(frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514947a4-12b4-491f-b13b-d7404312130c",
   "metadata": {},
   "source": [
    "### Instanzio una q-table random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e016780-c645-4188-beaf-49b4cf079896",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_table = np.zeros([env.observation_space.n, env.action_space.n])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d91478-40ec-4500-85a5-cf3f9049b8be",
   "metadata": {},
   "source": [
    "### Addestramento dell'agente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52e3ba2b-c52b-4dfd-b9b8-2780f1a1bc5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episodio:10000\n",
      "terminato\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gamma = 0.6  # Fattore di sconto \n",
    "epsilon = 0.1  # Fattore di esplorazione\n",
    "\n",
    "all_epochs = []\n",
    "all_penalties = []\n",
    "\n",
    "#Per ogni esempio \n",
    "for i in range(1, 10001):\n",
    "    state = env.reset()[0]  #Reset ambiente\n",
    "\n",
    "    #Inizializzazione Step, penalita e ricompense \n",
    "    steps, penalites, reward = 0,0,0\n",
    "    #done = False == Episodio non completo \n",
    "    done = False\n",
    "\n",
    "    #Finche l'episodio non sara completo \n",
    "    while not done:\n",
    "        # Numero casuale tra 0 e 1 e se e' minore di epsilon ossia del 10% effettuera un azione casuale ossia fara esplorazione\n",
    "        if random.uniform(0, 1) < epsilon:\n",
    "            action = env.action_space.sample()\n",
    "        else:\n",
    "            # Mentre 9 /10  volte effettura lo sfruttamento ossia utilizzera cio che gli viene consigliato \n",
    "            action = np.argmax(q_table[state]) # Sulla q-tabel nella riga dello stato attuale ho un elenco di colonne e prendo \n",
    "                                               # quella con il valore piu alto ossia id della colonna con il valore piu alto \n",
    "\n",
    "        next_state, reward, terminated, truncated, info = env.step(action)  # Eseguiamo l'azione precedentemente determinata\n",
    "        old_value = q_table[state, action] #Sara l'azione eseguita nello stato precedente preso dalla q-table\n",
    "        next_max = np.max(q_table[next_state]) # prendo la Q massima del nuovo stato dove sono entrato \n",
    "\n",
    "        new_value = reward + gamma * next_max # Applico Belman e dico che il valore di Q-table e' \n",
    "                                              # Il reward che ho ottenuto + il fattore di sconto * il massimo reward successivo allo \n",
    "                                              # allo stato attuale \n",
    "        # Lo implemento nella Q-table\n",
    "        q_table[state, action] = new_value\n",
    "\n",
    "        if reward == -10:\n",
    "            penalties += 1\n",
    "\n",
    "        state = next_state\n",
    "        steps += 1\n",
    "        done = terminated or truncated \n",
    "\n",
    "    # una volta chiuso l'episodio \n",
    "    if i % 100 == 0:\n",
    "        clear_output(wait= True)\n",
    "        print(f\"episodio:{i}\")\n",
    "\n",
    "print(\"terminato\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605a5fd4-4b6d-4af9-a53c-42cd0e439885",
   "metadata": {},
   "source": [
    "### Al termine dei nostri 10000 episodi la nostra Q-table e' addestrata "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d156deeb-93dc-4d55-9322-32fcf0770c54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -2.4936525 ,  -2.4936525 ,  -2.48236806,  -2.4936525 ,\n",
       "       -11.48942084, -11.48942084])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_table[224]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee80ea6d-8ad3-469e-a664-4e97e53bf9da",
   "metadata": {},
   "source": [
    "### Test dell'agente "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39bc5b16-6bab-4b19-a3e9-d6f799e8897d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step/episodio: 1.0\n",
      "penalita'/episodio: 0.0\n"
     ]
    }
   ],
   "source": [
    "total_steps, total_penalties = 0, 0\n",
    "episodies = 100 \n",
    "\n",
    "for _ in range(episodies):\n",
    "    state = env.reset()[0]   #Stato di partenza uno stato casuale \n",
    "    steps, penalties, reward = 0, 0, 0\n",
    "\n",
    "    done = False \n",
    "\n",
    "    while not done:\n",
    "        action = np.argmax(q_table[state])\n",
    "        state, reward, termionated, truncated, info = env.step(action)  \n",
    "\n",
    "        if reward == -10:\n",
    "            penalties += 1\n",
    "\n",
    "        steps += 1 \n",
    "\n",
    "        done = truncated or terminated\n",
    "\n",
    "    total_penalties += penalties\n",
    "    total_steps += steps\n",
    "\n",
    "print(f\"step/episodio: {total_steps / episodies}\")\n",
    "print(f\"penalita'/episodio: {total_penalties / episodies}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67700748-efcc-4c6e-a09f-bd46e682269c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
